{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ba3095",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Dynamic Discrete Choice Model with Harold Zurcher  in Rust (2077)\n",
    "## Presented by Ha Pham\n",
    "### AEM 7130 Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b40d7f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "- One of the most propular models when it comes to modeling dynamic decisions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244cf629",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Widely applied in different fields including labor, IO,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc4ba8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Introducing some key assumptions that leads to clean estimation routine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a1e09",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Weakness: cannot be applied in dynamic games (kinda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76eaf05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "- Model Setups \n",
    "- Applications\n",
    "- Implementation in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2597c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Background\n",
    "\n",
    "- Harold Zurcher is responsible for changing bus engines for Madison Metro in Madison, WI\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e03e8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Bus engines inherently get older, which makes them more costly to maintain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb386f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Replacing the engine require an upfront fixed cost and \"reset\" the age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ce245",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This forms a dynamic trade-off: paying the fixed cost today for cheaper maintainance tomorrow or saving the fixed cost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade64006",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Setup\n",
    "- Time is discrete and infinite: $t = \\{ 1,2,3,...,\\infty\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2c44c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- States are the discretized mileage of the engines: $s = \\{0,5000,10000,15000,...\\}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211af3ef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Actions are discrete choices: $a = {0,1}$ where $0 = \\textit{not replace}$ and $1 = replace$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5bd4bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Given the current state and action, the state will evolve according to a Markovian transtition probability matrix. \n",
    "- The entries of the matrix are: $p(s_{t+1} = s' | s_t = s, a_t = a)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265e6cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Timing \n",
    "1. States are observed \n",
    "2. Shocks are observed by the agent, econometrician knows the distribution\n",
    "3. Choices are made (and observed) to maximize utility\n",
    "4. States evolves according to the transition rule\n",
    "5. Next period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f50b0ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Period Payoff\n",
    "Each period, the agent earns some profit based on the state and the action:\n",
    "\n",
    "<center>$\\pi(s_t, a_t) +  \\epsilon_{ta} $</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948624f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decision Problem\n",
    "Write down the Bellman equation:\n",
    "Each period, the action will maximize the expected utility. The strategy $a(.,.)$ will solve the problem:\n",
    "\n",
    "$ max ... $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f76366",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2202e60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Choice-specific Value Functions\n",
    "This is why the assumptions are lit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f67548",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Maximum Likelihood Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9f010",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Estimation Steps\n",
    "\n",
    "Now that have learned how to solve the model, how can we estimate the parameters from observed data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779fa2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 1: Estimate the state transition rule "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44e04b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 2: Compute Value Function given parameters (Inner Loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3b8cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 3: Searching for the parameters by ML (Outer Loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb623e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applications\n",
    "\n",
    "- IO:\n",
    "  - Investment Decision: Rust (1987), \n",
    "  - Innovation: Igami ()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4f696",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Energy & Environmental:\n",
    "  - Eiseinberg ()\n",
    "  - Cullen (2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9fd215",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Labor:\n",
    "  - Rust ...\n",
    "  - ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ef2cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "- Rust (1987) provides an estimation routine that is still widely used today\n",
    "- This is the basic model, there are several extensions to the model such as Hotz & Miller\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
